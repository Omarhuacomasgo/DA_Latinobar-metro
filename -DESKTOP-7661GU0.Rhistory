# Apoyo específico
p12stgbsa, # Satisfacción democrática
# Sociodem
numinves, idenpa, reg, ciudad, tamciud, edad, sexo,
s2, s11, s15a, s18a,s24, reedad,
# Controles
) %>%
mutate(edad = as.numeric(edad)) %>% mutate(
across(.cols = where(haven::is.labelled),.fns  = ~ haven::as_factor(.x, levels = "labels"))
) %>% filter (idenpa == " Peru")
# ── Escalas ordinales ──────────────────────────────────────────────────────
ord_foursteps     <- c("Ninguna", "Poca", "Algo", "Mucha")
cs_subjective_ord <- c("Baja", "Media Baja", "Media", "Media Alta", "Alta")
justice_ord       <- c("Muy injusta", "Injusta", "Justa", "Muy justa")
ord_satis         <- c("Nada satisfecho", "No muy satisfecho", "Mas bien satisfecho", "Muy satisfecho")
ord_agree         <- c("Muy en desacuerdo", "En desacuerdo", "De acuerdo", "Muy de acuerdo")
educ_ord <- c("Analfabeto", "Basica incompleta", "Basica completa", "Secundaria, media, tecnica incompleta",
"Secundaria, media, tecnica completa",  "Superior Incompleta",  "Superior completa")
# Categorías “desconocidas”
unknown_cat <- c("^no sabe", "^no contesta", "^no aplicable", "^no preguntada", "^sin dato",
"no menciona", "vota nulo", "ningun partido")
# Funciones auxiliares (sin cambios)
normaliza   <- function(x) { x %>% stringr::str_trim() %>% stringr::str_squish() %>%
stringi::stri_trans_general("Latin-ASCII") %>%
stringr::str_to_lower() }
niveles_ok  <- function(v, ref) all(stats::na.omit(v) %in% ref)
# ── Recodificación unificada
lb24_nm<- lb24_nm %>%
dplyr::mutate(
dplyr::across(
.cols = where(base::is.factor),
.fns  = ~ {
x_chr  <- base::as.character(.x)
x_norm <- normaliza(x_chr)
# 1) Reemplazar categorías desconocidas por NA
x_chr[stringr::str_detect(
x_norm, stringr::str_c(unknown_cat, collapse = "|"))] <- NA_character_
# 2) Reconstruir factor ordenado si corresponde a alguna escala
if      (niveles_ok(x_chr, ord_foursteps))
base::factor(x_chr, levels = ord_foursteps, ordered = TRUE)
else if (niveles_ok(x_chr, cs_subjective_ord))
base::factor(x_chr, levels = cs_subjective_ord, ordered = TRUE)
else if (niveles_ok(x_chr, justice_ord))
base::factor(x_chr, levels = justice_ord, ordered = TRUE)
else if (niveles_ok(x_chr, ord_satis))
base::factor(x_chr, levels = ord_satis, ordered = TRUE)
else if (niveles_ok(x_chr, ord_agree))
base::factor(x_chr, levels = ord_agree, ordered = TRUE)
else if (niveles_ok(x_chr, educ_ord))              # ← añadido
base::factor(x_chr, levels = educ_ord, ordered = TRUE)
else
base::factor(x_chr)                              # sin orden específico
}
)
) %>%
# 3) Eliminar niveles que quedaron vacíos
dplyr::mutate(
dplyr::across(where(base::is.factor), forcats::fct_drop)
)
#| label: imputation-setup
# Vector para personalizar las variables a imputar.
# El usuario debe listar aquí las columnas que quiere rellenar.
vars_to_impute <- c("p22n", "p20st", "p18std", "p18stc", "s2", "s11", "s15a", "s18a")
# Filtrar el dataset para trabajar solo con las variables relevantes + identificadores
data_for_imputation <- lb24_nm %>%
dplyr::select(
numinves, # Se mantiene como identificador, pero no se usará como predictor
all_of(vars_to_impute)
)
# Clasificar las variables a imputar según su tipo
numeric_vars     <- names(which(sapply(data_for_imputation[vars_to_impute], is.numeric)))
ordinal_vars     <- names(which(sapply(data_for_imputation[vars_to_impute], is.ordered)))
categorical_vars <- names(which(sapply(data_for_imputation[vars_to_impute], function(x) is.factor(x) && !is.ordered(x))))
#| label: imputation-run
# --- Definir métodos de imputación ---
# Se crea un vector de métodos solo para las variables que vamos a imputar.
meth_vec <- character(ncol(data_for_imputation))
names(meth_vec) <- colnames(data_for_imputation)
meth_vec[numeric_vars]     <- "pmm"
meth_vec[ordinal_vars]     <- "polr"
meth_vec[categorical_vars] <- "polyreg"
# --- Configurar la matriz de predictores ---
# Empezamos con la matriz por defecto
pred_matrix <- make.predictorMatrix(data_for_imputation)
# Excluimos variables que no deben ser predictoras (ej. IDs)
pred_matrix[, "numinves"] <- 0
# --- Ejecutar la imputación ---
# Aumentamos maxit para una mejor convergencia
imputed_data_mice <- mice(
data_for_imputation,
method = meth_vec,
predictorMatrix = pred_matrix,
m = 10,         # Número de imputaciones
maxit = 20,       # Aumentado de 5 a 20 iteraciones
seed = 123,
printFlag = FALSE
)
View(lb24_nm)
cat("Imputación completada.\n")
View(lb24_nm)
skimr::skim(lb24_nm)
#| label: imputation-setup
# Vector para personalizar las variables a imputar.
# El usuario debe listar aquí las columnas que quiere rellenar.
vars_to_impute <- c("p22n", "p20st", "p18std", "p18stc", "p18sta" , "p12stgtbsa", "s2", "s11", "s15a", "s18a")
# Filtrar el dataset para trabajar solo con las variables relevantes + identificadores
data_for_imputation <- lb24_nm %>%
dplyr::select(
numinves, # Se mantiene como identificador, pero no se usará como predictor
all_of(vars_to_impute)
)
lb24_nm <- lb2024 %>% dplyr:: select(
# Apoyo a las instituciones electorales
p22n, # Criticar al gobierno- apo.libertad expresión
p20st, # partidos políticos - apo.libertad de asoc
p18std, # gob. tecnocrático - apo.elección de tomadores de decisi.
# Apoyo a las instituciones liberales
p18stc, # aplicacion de la ley - apo.igualdad ante la ley
# Apoyo difuso
p18sta, # Churchill
p18stb, # No me importaría que un gobienro no democrático
# Apoyo específico
p12stgbsa, # Satisfacción democrática
# Sociodem
numinves, idenpa, reg, ciudad, tamciud, edad, sexo,
s2, s11, s15a, s18a,s24, reedad,
# Controles
) %>%
mutate(edad = as.numeric(edad)) %>% mutate(
across(.cols = where(haven::is.labelled),.fns  = ~ haven::as_factor(.x, levels = "labels"))
) %>% filter (idenpa == " Peru")
# ── Escalas ordinales ──────────────────────────────────────────────────────
ord_foursteps     <- c("Ninguna", "Poca", "Algo", "Mucha")
cs_subjective_ord <- c("Baja", "Media Baja", "Media", "Media Alta", "Alta")
justice_ord       <- c("Muy injusta", "Injusta", "Justa", "Muy justa")
ord_satis         <- c("Nada satisfecho", "No muy satisfecho", "Mas bien satisfecho", "Muy satisfecho")
ord_agree         <- c("Muy en desacuerdo", "En desacuerdo", "De acuerdo", "Muy de acuerdo")
educ_ord <- c("Analfabeto", "Basica incompleta", "Basica completa", "Secundaria, media, tecnica incompleta",
"Secundaria, media, tecnica completa",  "Superior Incompleta",  "Superior completa")
# Categorías “desconocidas”
unknown_cat <- c("^no sabe", "^no contesta", "^no aplicable", "^no preguntada", "^sin dato",
"no menciona", "vota nulo", "ningun partido")
# Funciones auxiliares (sin cambios)
normaliza   <- function(x) { x %>% stringr::str_trim() %>% stringr::str_squish() %>%
stringi::stri_trans_general("Latin-ASCII") %>%
stringr::str_to_lower() }
niveles_ok  <- function(v, ref) all(stats::na.omit(v) %in% ref)
# ── Recodificación unificada
lb24_nm<- lb24_nm %>%
dplyr::mutate(
dplyr::across(
.cols = where(base::is.factor),
.fns  = ~ {
x_chr  <- base::as.character(.x)
x_norm <- normaliza(x_chr)
# 1) Reemplazar categorías desconocidas por NA
x_chr[stringr::str_detect(
x_norm, stringr::str_c(unknown_cat, collapse = "|"))] <- NA_character_
# 2) Reconstruir factor ordenado si corresponde a alguna escala
if      (niveles_ok(x_chr, ord_foursteps))
base::factor(x_chr, levels = ord_foursteps, ordered = TRUE)
else if (niveles_ok(x_chr, cs_subjective_ord))
base::factor(x_chr, levels = cs_subjective_ord, ordered = TRUE)
else if (niveles_ok(x_chr, justice_ord))
base::factor(x_chr, levels = justice_ord, ordered = TRUE)
else if (niveles_ok(x_chr, ord_satis))
base::factor(x_chr, levels = ord_satis, ordered = TRUE)
else if (niveles_ok(x_chr, ord_agree))
base::factor(x_chr, levels = ord_agree, ordered = TRUE)
else if (niveles_ok(x_chr, educ_ord))              # ← añadido
base::factor(x_chr, levels = educ_ord, ordered = TRUE)
else
base::factor(x_chr)                              # sin orden específico
}
)
) %>%
# 3) Eliminar niveles que quedaron vacíos
dplyr::mutate(
dplyr::across(where(base::is.factor), forcats::fct_drop)
)
skimr::skim(lb24_nm)
#| label: imputation-setup
# Vector para personalizar las variables a imputar.
# El usuario debe listar aquí las columnas que quiere rellenar.
vars_to_impute <- c("p22n", "p20st", "p18std", "p18stc", "p18sta" , "p12stgtbsa", "s2", "s11", "s15a", "s18a")
# Filtrar el dataset para trabajar solo con las variables relevantes + identificadores
data_for_imputation <- lb24_nm %>%
dplyr::select(
numinves, # Se mantiene como identificador, pero no se usará como predictor
all_of(vars_to_impute)
)
#| label: imputation-setup
# Vector para personalizar las variables a imputar.
# El usuario debe listar aquí las columnas que quiere rellenar.
vars_to_impute <- c("p22n", "p20st", "p18std", "p18stc", "p18sta" , "p12stgbsa", "s2", "s11", "s15a", "s18a")
# Filtrar el dataset para trabajar solo con las variables relevantes + identificadores
data_for_imputation <- lb24_nm %>%
dplyr::select(
numinves, # Se mantiene como identificador, pero no se usará como predictor
all_of(vars_to_impute)
)
# Clasificar las variables a imputar según su tipo
numeric_vars     <- names(which(sapply(data_for_imputation[vars_to_impute], is.numeric)))
ordinal_vars     <- names(which(sapply(data_for_imputation[vars_to_impute], is.ordered)))
categorical_vars <- names(which(sapply(data_for_imputation[vars_to_impute], function(x) is.factor(x) && !is.ordered(x))))
#| label: imputation-run
# --- Definir métodos de imputación ---
# Se crea un vector de métodos solo para las variables que vamos a imputar.
meth_vec <- character(ncol(data_for_imputation))
names(meth_vec) <- colnames(data_for_imputation)
meth_vec[numeric_vars]     <- "pmm"
meth_vec[ordinal_vars]     <- "polr"
meth_vec[categorical_vars] <- "polyreg"
# --- Configurar la matriz de predictores ---
# Empezamos con la matriz por defecto
pred_matrix <- make.predictorMatrix(data_for_imputation)
# Excluimos variables que no deben ser predictoras (ej. IDs)
pred_matrix[, "numinves"] <- 0
# --- Ejecutar la imputación ---
# Aumentamos maxit para una mejor convergencia
imputed_data_mice <- mice(
data_for_imputation,
method = meth_vec,
predictorMatrix = pred_matrix,
m = 10,         # Número de imputaciones
maxit = 20,       # Aumentado de 5 a 20 iteraciones
seed = 123,
printFlag = FALSE
)
cat("Imputación completada.\n")
#| label: imputation-run
# --- Definir métodos de imputación ---
# Se crea un vector de métodos solo para las variables que vamos a imputar.
meth_vec <- character(ncol(data_for_imputation))
names(meth_vec) <- colnames(data_for_imputation)
meth_vec[numeric_vars]     <- "pmm"
meth_vec[ordinal_vars]     <- "polr"
meth_vec[categorical_vars] <- "polyreg"
# --- Configurar la matriz de predictores ---
# Empezamos con la matriz por defecto
pred_matrix <- make.predictorMatrix(data_for_imputation)
# Excluimos variables que no deben ser predictoras (ej. IDs)
pred_matrix[, "numinves"] <- 0
# --- Ejecutar la imputación ---
# Aumentamos maxit para una mejor convergencia
imputed_data_mice <- mice(
data_for_imputation,
method = meth_vec,
predictorMatrix = pred_matrix,
m = 10,         # Número de imputaciones
maxit = 20,       # Aumentado de 5 a 20 iteraciones
seed = 123,
printFlag = FALSE
)
cat("Imputación completada.\n")
#| label: imputation-diagnostics
#| fig-cap: "Gráficos de diagnóstico del proceso de imputación."
#| layout-ncol: 2
# 1. Gráfico de Convergencia
# Las líneas de diferentes colores (cada una es una imputación) deben mezclarse
# bien, sin mostrar tendencias claras. Esto indica que el algoritmo convergió.
plot(imputed_data_mice, main = "Convergencia de las Cadenas de Imputación")
# 2. Gráfico de Densidad
# Compara la distribución de los datos observados (azul) con los imputados (rojo).
# Idealmente, las distribuciones deben solaparse lo más posible.
densityplot(imputed_data_mice)
#| label: final-dataset
# --- Creación de un único dataset completo ---
# Se recomienda para visualización o reportes descriptivos.
# Para análisis inferencial, usar el objeto 'imputed_data_mice' con pool().
lb24_nm_imputed <- complete(imputed_data_mice, 1) # Usamos la primera imputación
# Unimos las variables imputadas con las que no necesitaron imputación del dataset original
final_df <- lb24_nm %>%
dplyr::select(-all_of(vars_to_impute)) %>%
dplyr::bind_cols(lb24_nm_imputed %>% select(all_of(vars_to_impute)))
cat("Dimensiones del dataset original:", dim(lb24_nm), "\n")
cat("Dimensiones del dataset final imputado:", dim(final_df), "\n")
cat("Valores perdidos restantes en el dataset final:", sum(is.na(final_df)), "\n")
#| label: visualization-comparison
#| fig-cap: "Comparación de distribuciones de variables categóricas (Original vs. Imputado)."
#| fig-height: 10
#| fig-width: 12
# --- Preparar datos para el gráfico ---
original_long <- lb24_nm %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
filter(!is.na(categoria)) %>%
mutate(Fuente = "Original")
imputed_long <- final_df %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
mutate(Fuente = "Imputada")
# Combinar ambos datasets
comparison_df <- bind_rows(original_long, imputed_long) %>%
count(variable, categoria, Fuente) %>%
group_by(variable, Fuente) %>%
mutate(proporcion = n / sum(n)) %>%
ungroup()
# --- Graficar ---
ggplot(comparison_df, aes(x = fct_reorder(categoria, proporcion), y = proporcion, fill = Fuente)) +
geom_col(position = "dodge") +
facet_wrap(~ variable, scales = "free") +
scale_y_continuous(labels = scales::percent_format()) +
coord_flip() +
labs(
title = "Distribución de Proporciones: Original vs. Dataset Imputado",
subtitle = "La distribución de los datos imputados debería ser similar a la original.",
x = "Categoría",
y = "Proporción",
fill = "Fuente de Datos"
) +
theme_minimal(base_size = 12) +
theme(
legend.position = "top",
strip.text = element_text(face = "bold")
)
#| label: visualization-comparison
#| fig-cap: "Comparación de distribuciones de variables categóricas (Original vs. Imputado)."
#| fig-height: 10
#| fig-width: 12
# --- Preparar datos para el gráfico ---
original_long <- lb24_nm %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
filter(!is.na(categoria)) %>%
mutate(Fuente = "Original")
imputed_long <- final_df %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
mutate(Fuente = "Imputada")
# Combinar ambos datasets
comparison_df <- bind_rows(original_long, imputed_long) %>%
count(variable, categoria, Fuente) %>%
group_by(variable, Fuente) %>%
mutate(proporcion = n / sum(n)) %>%
ungroup()
# --- Graficar ---
ggplot(comparison_df, aes(x = fct_reorder(categoria, proporcion), y = proporcion, fill = Fuente)) +
geom_col(position = "dodge") +
facet_wrap(~ variable, scales = "free") +
scale_y_continuous(labels = scales::percent_format()) +
coord_flip() +
labs(
title = "Distribución de Proporciones: Original vs. Dataset Imputado",
subtitle = "La distribución de los datos imputados debería ser similar a la original.",
x = "Categoría",
y = "Proporción",
fill = "Fuente de Datos"
) +
theme_minimal(base_size = 12) +
theme(
legend.position = "top",
strip.text = element_text(face = "bold")
)
#| label: final-dataset
# --- Creación de un único dataset completo ---
# Se recomienda para visualización o reportes descriptivos.
# Para análisis inferencial, usar el objeto 'imputed_data_mice' con pool().
lb24_nm_imputed <- complete(imputed_data_mice, 1) # Usamos la primera imputación
# Unimos las variables imputadas con las que no necesitaron imputación del dataset original
final_df <- lb24_nm %>%
dplyr::select(-all_of(vars_to_impute)) %>%
dplyr::bind_cols(lb24_nm_imputed %>% select(all_of(vars_to_impute)))
cat("Dimensiones del dataset original:", dim(lb24_nm), "\n")
cat("Dimensiones del dataset final imputado:", dim(final_df), "\n")
cat("Valores perdidos restantes en el dataset final:", sum(is.na(final_df)), "\n")
#| label: visualization-comparison
#| fig-cap: "Comparación de distribuciones de variables categóricas (Original vs. Imputado)."
#| fig-height: 10
#| fig-width: 12
# --- Preparar datos para el gráfico ---
original_long <- lb24_nm %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
filter(!is.na(categoria)) %>%
mutate(Fuente = "Original")
imputed_long <- final_df %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
mutate(Fuente = "Imputada")
# Combinar ambos datasets
comparison_df <- bind_rows(original_long, imputed_long) %>%
count(variable, categoria, Fuente) %>%
group_by(variable, Fuente) %>%
mutate(proporcion = n / sum(n)) %>%
ungroup()
# --- Graficar ---
ggplot(comparison_df, aes(x = fct_reorder(categoria, proporcion), y = proporcion, fill = Fuente)) +
geom_col(position = "dodge") +
facet_wrap(~ variable, scales = "free") +
scale_y_continuous(labels = scales::percent_format()) +
coord_flip() +
labs(
title = "Distribución de Proporciones: Original vs. Dataset Imputado",
subtitle = "La distribución de los datos imputados debería ser similar a la original.",
x = "Categoría",
y = "Proporción",
fill = "Fuente de Datos"
) +
theme_minimal(base_size = 12) +
theme(
legend.position = "top",
strip.text = element_text(face = "bold")
)
#| label: visualization-comparison
#| fig-cap: "Comparación de distribuciones de variables categóricas (Original vs. Imputado)."
#| fig-height: 10
#| fig-width: 12
# --- Preparar datos para el gráfico ---
original_long <- lb24_nm %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
filter(!is.na(categoria)) %>%
mutate(Fuente = "Original")
imputed_long <- final_df %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
mutate(Fuente = "Imputada")
# Combinar ambos datasets
comparison_df <- bind_rows(original_long, imputed_long) %>%
count(variable, categoria, Fuente) %>%
group_by(variable, Fuente) %>%
mutate(proporcion = n / sum(n)) %>%
ungroup()
# --- Graficar ---
ggplot(comparison_df, aes(x = fct_reorder(categoria, proporcion), y = proporcion, fill = Fuente)) +
geom_col(position = "dodge") +
facet_wrap(~ variable, scales = "free") +
scale_y_continuous(labels = scales::percent_format()) +
coord_flip() +
labs(
title = "Distribución de Proporciones: Original vs. Dataset Imputado",
subtitle = "La distribución de los datos imputados debería ser similar a la original.",
x = "Categoría",
y = "Proporción",
fill = "Fuente de Datos"
) +
theme_minimal(base_size = 12) +
theme(
legend.position = "top",
strip.text = element_text(face = "bold")
)
## Comparación Visual: Antes y Después
Reutilizamos tu excelente código de visualización para comparar las distribuciones de las variables categóricas, pero ahora generando un gráfico para cada variable.
## Comparación Visual: Antes y Después
Reutilizamos tu excelente código de visualización para comparar las distribuciones de las variables categóricas, pero ahora generando un gráfico para cada variable.
## Comparación Visual: Antes y Después
#| label: visualization-comparison-individual
#| fig-cap: "Comparación de distribuciones para cada variable categórica (Original vs. Imputado)."
#| fig-height: 6
#| fig-width: 10
# --- Preparar datos para el gráfico ---
original_long <- lb24_nm %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
filter(!is.na(categoria)) %>%
mutate(Fuente = "Original")
imputed_long <- final_df %>%
select(any_of(c(categorical_vars, ordinal_vars))) %>%
mutate(across(everything(), as.character)) %>%
pivot_longer(everything(), names_to = "variable", values_to = "categoria") %>%
mutate(Fuente = "Imputada")
# Combinar ambos datasets
comparison_df <- bind_rows(original_long, imputed_long) %>%
count(variable, categoria, Fuente) %>%
group_by(variable, Fuente) %>%
mutate(proporcion = n / sum(n)) %>%
ungroup()
# --- Graficar un gráfico por cada variable ---
# Obtenemos la lista única de variables a graficar
vars_to_plot <- unique(comparison_df$variable)
# Iteramos sobre cada variable y creamos un gráfico
for (var in vars_to_plot) {
# Filtramos los datos para la variable actual
plot_data <- comparison_df %>%
filter(variable == var)
# Creamos el gráfico
p <- ggplot(plot_data, aes(x = fct_reorder(categoria, proporcion), y = proporcion, fill = Fuente)) +
geom_col(position = "dodge") +
scale_y_continuous(labels = scales::percent_format()) +
coord_flip() +
labs(
title = paste("Distribución de Proporciones para la Variable:", var),
subtitle = "La distribución de los datos imputados debería ser similar a la original.",
x = "Categoría",
y = "Proporción",
fill = "Fuente de Datos"
) +
theme_minimal(base_size = 12) +
theme(
legend.position = "top",
plot.title = element_text(face = "bold")
)
# Imprimimos el gráfico
print(p)
}
#| label: imputation-diagnostics
#| fig-cap: "Gráficos de diagnóstico del proceso de imputación."
#| layout-ncol: 2
# 1. Gráfico de Convergencia
# Las líneas de diferentes colores (cada una es una imputación) deben mezclarse
# bien, sin mostrar tendencias claras. Esto indica que el algoritmo convergió.
plot(imputed_data_mice, main = "Convergencia de las Cadenas de Imputación")
